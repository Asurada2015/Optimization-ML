# Bibliography

> Optimization-ML, see for more detail notes on [Reading_Notes](./Reading_Notes.md)

Contributed by Xi Lin, Zhiyuan Yang, and Huiling Zhen.


# Table of contents

- [Multi Task Learning](#Multi-Task-Learning)

  

## [Multi Task Learning](#Table-of-contents)

### Survey

- [A Survey on Multi-Task Learning](https://arxiv.org/abs/1707.08114), Yu Zhang and Qiang Yang **`(2017)`**
- [An Overview of Multi-Task Learning in Deep Neural Networks](https://arxiv.org/abs/1706.05098), Sebastian Ruder **`(2017)`**
- [Multi-Task Learning for Dense Prediction Tasks: A Survey](https://arxiv.org/abs/2004.13379v2), Simon Vandenhende, Stamatios Georgoulis, Wouter Van Gansbeke, Marc Proesmans, Dengxin Dai, Luc Van Gool **`(2020)`**
- [Multi-Task Learning with Deep Neural Networks A Survey](https://arxiv.org/abs/2009.09796), Michael Crawshaw **`(2020)`**

### Adaptive Weights
- **`Linear`** [Multitask learning](https://people.eecs.berkeley.edu/~russell/classes/cs294/f05/papers/caruana-1997.pdf), Rich Caruana **`(1997)`** **`[MLJ]`**
- **`Uncertainty`** [Multi-Task Learning using Uncertainty to Weigh Losses for Scene Geometry and Semantics](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf), Alex Kendall, Yarin Gal, and Roberto Cipolla **`[CVPR 2018]`**
- **`Gradnorm`** [Gradnorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks](http://proceedings.mlr.press/v80/chen18a/chen18a.pdf), Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich **`[ICML 2018]`**
- **`DWA`** [End-to-End Multi-Task Learning with Attention](https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_End-To-End_Multi-Task_Learning_With_Attention_CVPR_2019_paper.pdf), Shikun Liu, Edward Johns, and Andrew J. Davison **`[CVPR 2019]`**
- **`PCGrad`** [Gradient Surgery for Multi-Task Learning](https://arxiv.org/abs/2001.06782), Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn **`[NeurIPS 2020]`**
- [Understanding and Improving Information Transfer in Multi-Task Learning](https://arxiv.org/abs/2005.00944), Sen Wu, Hongyang R. Zhang, Christopher RÃ© **`[ICLR 2020]`**


### Multiobjective Optimization
- **`MGDA`** [Multi-Task Learning as Multi-Objective Optimization](https://arxiv.org/abs/1810.04650), Ozan Sener and Vladlen Koltun **`[NeurIPS 2018]`**

- **`Pareto MTL`** [Pareto Multi-Task Learning](https://arxiv.org/abs/1912.12854), Xi Lin, Huiling Zhen, Zhenhua Li, Qingfu Zhang, and Sam Kwong **`[NeurIPS 2019]`**

- [Efficient Continuous Pareto Exploration in Multi-Task Learning](https://arxiv.org/abs/2006.16434), Pingchuan Ma, Tao Du, andWojciech Matusik **`[ICML 2020]`**

- **`EPO`** [Multi-Task Learning with User Preferences: Gradient Descent with Controlled Ascent in Pareto Optimization](https://proceedings.icml.cc/static/paper_files/icml/2020/3635-Paper.pdf), Debabrata Mahapatra and Vaibhav Rajan **`[ICML 2020]`**


### Task Relation
- **`Taskonomy`** [Taskonomy: Disentangling task transfer learning](https://arxiv.org/abs/1804.08328), Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese **`[CVPR 2018]`**

- [Which tasks should be learned together in multi-task learning?](https://arxiv.org/abs/1905.07553), Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese **`[ICML 2020]`**

### Applications

- NLP

	- **`Bert`** [Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805), Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova **`[NAACL-HLT 2019]`**

