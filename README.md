# Bibliography

> Optimization-ML, see for more detail notes on [Reading_Notes](./Reading_Notes.md)

Contributed by Xi Lin, Zhiyuan Yang, and Huiling Zhen.


# Table of contents

- [Multi Task Learning](#Multi-Task-Learning)

  

## [Multi Task Learning](#Table-of-contents)

### Survey

- [A Survey on Multi-Task Learning](https://arxiv.org/abs/1707.08114), Yu Zhang and Qiang Yang **`(2017)`**
- [An Overview of Multi-Task Learning in Deep Neural Networks](https://arxiv.org/abs/1706.05098), Sebastian Ruder **`(2017)`**
- [Multi-Task Learning for Dense Prediction Tasks: A Survey](https://arxiv.org/abs/2004.13379v2), Simon Vandenhende **`(2020)`**
- [Multi-Task Learning with Deep Neural Networks A Survey](https://arxiv.org/abs/2009.09796), Michael Crawshaw **`(2020)`**

### Adaptive Weights
- **`Linear`** [Multitask learning](https://people.eecs.berkeley.edu/~russell/classes/cs294/f05/papers/caruana-1997.pdf), Rich Caruana **`(1997)`** **`[MLJ]`**

- **`Uncertainty`** [Multi-Task Learning using Uncertainty to Weigh Losses for Scene Geometry and Semantics](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf), Alex Kendall, Yarin Gal, and Roberto Cipolla **`(2018)`** **`[CVPR2018]`**

- **`Gradnorm`** [Gradnorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks](http://proceedings.mlr.press/v80/chen18a/chen18a.pdf), Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich **`(2018)`** **`[ICML2018]`**

- **`DWA`** [End-to-End Multi-Task Learning with Attention](https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_End-To-End_Multi-Task_Learning_With_Attention_CVPR_2019_paper.pdf), Shikun Liu, Edward Johns, and Andrew J. Davison **`(2019)`** **`[CVPR2019]`**

- **`PCGrad`** [Gradient Surgery for Multi-Task Learning](https://arxiv.org/abs/2001.06782), Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn **`(2020)`** **`[NeurIPS2020]`**


### Multiobjective Optimization
- **`MGDA`** [Multi-Task Learning as Multi-Objective Optimization](https://arxiv.org/abs/1810.04650), Ozan Sener and Vladlen Koltun **`(2018)`** **`[NeurIPS2018]`**

- **`Pareto MTL`** [Pareto Multi-Task Learning](https://arxiv.org/abs/1912.12854), Xi Lin, Huiling Zhen, Zhenhua Li, Qingfu Zhang, and Sam Kwong **`(2019)`** **`[NeurIPS2019]`**

- [Efficient Continuous Pareto Exploration in Multi-Task Learning](https://arxiv.org/abs/2006.16434), Pingchuan Ma, Tao Du, andWojciech Matusik **`(2020)`** **`[ICML2020]`**

- **`EPO`** [Multi-Task Learning with User Preferences: Gradient Descent with Controlled Ascent in Pareto Optimization](https://proceedings.icml.cc/static/paper_files/icml/2020/3635-Paper.pdf), Debabrata Mahapatra and Vaibhav Rajan **`(2020)`** **`[ICML2020]`**


### Task Relation
- **`Taskonomy`** [Taskonomy: Disentangling task transfer learning](https://arxiv.org/abs/1804.08328), Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese **`(2018)`** **`[CVPR2018]`**

- [Which tasks should be learned together in multi-task learning?](https://arxiv.org/abs/1905.07553), Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese **`(2020)`** **`[ICML2020]`**

